{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import np_utils\n",
    "# Plot ad hoc mnist instances\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(221)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,) (10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# flatten 28*28 images to a 784 vector for each image\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')\n",
    "\n",
    "print(X_train.shape , y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.2837 - accuracy: 0.9197 - val_loss: 0.1320 - val_accuracy: 0.9620\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.1119 - accuracy: 0.9676 - val_loss: 0.0923 - val_accuracy: 0.9729\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.0728 - accuracy: 0.9786 - val_loss: 0.0823 - val_accuracy: 0.9744\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0511 - accuracy: 0.9849 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0364 - accuracy: 0.9896 - val_loss: 0.0655 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0272 - accuracy: 0.9928 - val_loss: 0.0652 - val_accuracy: 0.9786\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0567 - val_accuracy: 0.9815\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.0138 - accuracy: 0.9970 - val_loss: 0.0602 - val_accuracy: 0.9809\n",
      "Epoch 9/10\n",
      " - 5s - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0619 - val_accuracy: 0.9805\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0665 - val_accuracy: 0.9802\n",
      "Baseline Error: 1.98%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 442us/step - loss: 0.2498 - accuracy: 0.9290 - val_loss: 0.0811 - val_accuracy: 0.9752\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 0.0738 - accuracy: 0.9775 - val_loss: 0.0478 - val_accuracy: 0.9849\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.0508 - accuracy: 0.9847 - val_loss: 0.0462 - val_accuracy: 0.9842\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.0362 - val_accuracy: 0.9879\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.0381 - val_accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 27s 454us/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0326 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.0231 - accuracy: 0.9929 - val_loss: 0.0345 - val_accuracy: 0.9889\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0367 - val_accuracy: 0.9885\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0395 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.0350 - val_accuracy: 0.9893\n",
      "CNN Error: 1.07%\n"
     ]
    }
   ],
   "source": [
    "# Simple CNN for the MNIST Dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# reshape to be [samples][width][height][channels]\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "# define a simple CNN model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D())\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonathan\\Anaconda6\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:104: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    "\tplt.imshow(img)\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 1 channel\n",
    "\timg = img.reshape(1, 28, 28, 1)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\timg = img / 255.0\n",
    "\treturn img\n",
    "\n",
    "def run_example():\n",
    "\t# load the image\n",
    "\timgx = load_image('C:\\\\Users\\\\Jonathan\\\\computer vision\\\\mnist\\\\sample_image.png')\n",
    "\t# load model\n",
    "\tmodel = load_model('final_model.h5')\n",
    "\t# predict the class\n",
    "\tdigit = model.predict_classes(imgx)\n",
    "\tprint(digit[0])\n",
    " \n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
